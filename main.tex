% !TeX root = main.tex
\documentclass[11pt,a4paper,UTF8]{ctexart}
\usepackage{quicklatex} % 引入自定义样式

\title{端侧文生多模态大模型文献综述}
\author{邱梓豪}
\date{\today}

\begin{document}



\maketitle
\tableofcontents
\newpage

\section{扩散模型基础}

在本文中，我们首先提供一个简洁但完善的扩散模型的基础知识介绍，它涵盖三种主要形式：去噪扩散概率模型（Denoising Diffusion Probabilistic Models，DDPMs）\cite{sohldickstein2015diffusion,ho2020denoising}、基于分数的生成模型（Score-based Generative Models，SGMs）\cite{song2019generative,song2020improved}以及随机微分方程（Stochastic Differential Equations，Score SDEs）\cite{song2020score}。这些方法的核心思想是通过逐渐增强的随机噪声对数据进行扰动（称为“扩散”过程），然后逐步去除噪声以生成新的数据样本。我们阐明了它们如何在相同的扩散原理下工作，并解释了这三种模型如何相互关联并可以相互转化。

我们首先定义扩散模型中的常用符号。设离散时间变量为$t\in\{0,1,\cdots,T\}$，连续时间变量为$t\in[0,T]$。设原始数据$\x_0\in\R^d$，其分布服从$q(\x_0)$，扩散模型通过向原始数据中不断加入高斯噪声，生成数据轨迹$\{\x_0,\x_1,\cdots,\x_T\}$，最终产生的$\x_T$趋近于纯高斯噪声。为了控制高斯噪声的添加强度，通常采用$\beta_t$（离散场景）或$\beta(t)dt$（连续场景）进行噪声调度。

\subsection{去噪扩散概率模型 (DDPM)}

去噪扩散概率模型（DDPM）使用两个马尔可夫链：一条前向链扰动数据直到变成噪声，另一条反向链将噪声转换回数据。前向链通常是人工设计的，目的是将任意数据分布转化为一个简单的先验分布（例如标准高斯分布），而反向马尔可夫链则通过学习由深度神经网络参数化的转移核（transition kernel）来逆转前向链的过程。随后，生成新数据点的过程首先从先验分布中采样一个随机向量，然后通过反向马尔可夫链进行采样，其中每一步都基于上一步的结果，该采样方式也称为\emph{祖先采样}\cite{koller2009probabilistic}。

下面我们给出上述过程的数学描述，给定数据分布$\x_0\sim q(\x_0)$，前向马尔可夫过程通过转移核$q(\x_t|\x_{t-1})$定义，并由此生成数据轨迹$\{\x_0,\x_1,\cdots,\x_T\}$。又马尔可夫性质，我们有：
\begin{equation*}
    q(\x_1,\cdots,\x_T|\x_0)=\Pi_{t=1}^T q(\x_t|\x_{t-1}).
\end{equation*}

在DDPM中，转移核$q(\x_t|\x_{t-1})$通常被设为高斯扰动形式，即：
\begin{equation}
    q(\x_t|\x_{t-1}) =\N(\x_t;\sqrt{1-\beta_t}\x_{t-1},\beta_t\mathbf{I}),
\label{ddpm:forward_process}
\end{equation}
其中$\beta_t\in(0,1)$是用于噪声调度的超参数，并在模型训练前被设置好,$\mathbf{I}$是单位对角矩阵。根据Sohl-Dickstein等人\cite{sohldickstein2015diffusion}的结论，使用上面的高斯扰动转移核的好处在于我们可以方便地获得某时间步$t\in\{0,1,\cdots,T\}$的数据$\x_t$的边缘分布。具体地，我们有：
\begin{equation*}
    q(\x_t|\x_0)=\N(\x_t;\sqrt{\bar{\alpha_t}}\x_0,(1-\bar{\alpha_t})\mathbf{I}),
\end{equation*}
其中$\alpha_t:=1-\beta_t$，$\bar{\alpha}_t:=\Pi_{s=0}^t\alpha_s$。于是，给定$\x_0$，我们可以首先采样一个高斯向量$\epsilon\in\N(0,\mathbf{I})$，随后通过如下变换得到$\x_t$的采样：
\begin{equation*}
    \x_t=\sqrt{\bar{\alpha_t}}\x_0 + (1-\bar{\alpha_t})\epsilon.
\end{equation*}
不难看出，由于$\bar{\alpha}_T\approx 0$，所以$\x_T$近似于高斯分布，故有：$q(\x_T)=\int q(\x_T|\x_0)q(\x_0)d\x_0\approx \N(\x_T;\mathbf{0},\mathbf{I})$。

直观地说，前向过程会逐渐向数据中注入噪声，直到所有结构完全消失。为了生成新的数据样本，DDPMs首先从先验分布中生成一个无结构的噪声向量，然后通过运行一个可学习的马尔可夫链在时间反方向上逐步去除噪声。具体来说，反向马尔可夫链由先验分布$p(\x_T)=\N(\x_T;\mathbf{0},\mathbf{I})$和一个\emph{可学习}的转移核$p_{\theta}(\x_{t-1}|\x_t)$参数化。先验分布的形式被设定为$p(\x_T)=\N(\x_T;\mathbf{0},\mathbf{I})$是因为前向过程产生的$\x_T$满足$q(\x_T)\approx \N(\x_T;\mathbf{0},\mathbf{I})$。可学习的转移核$p_{\theta}(\x_{t-1}|\x_t)$的形式为：
\begin{equation*}
    p_{\theta}(\x_{t-1}|\x_t) = \N(\x_{t-1};\mu_{\theta}(\x_t,t),\Sigma_{\theta}(x_t,t)),
\end{equation*}
其中$\theta$表示模型参数，高斯均值$\mu_{\theta}(\x_t,t)$和方差$\Sigma_{\theta}(x_t,t))$函数由深度神经网络进行参数化，并以带噪声的数据样本$\x_t$和时间$t$为输入。假设我们可以充分学习$p_{\theta}(\x_{t-1}|\x_t)$，那么便可以通过先从$p(\x_T)=\N(\x_T;\mathbf{0},\mathbf{I})$采样$\x_T$，再迭代式地调用$p_{\theta}(\x_{t-1}|\x_t)$（直到$t=1$）来生成样本$\x_0$。

现在我们介绍扩散模型的训练过程，即如何学出一个好的$p_{\theta}(\x_{t-1}|\x_t)$。训练的核心思想是\emph{最大化数据对数似然的变分下界（Evidence Lower Bound, ELBO）}，具体地，给定数据$\x_0\sim q(\x_0)$，反向模型生成$\x_0$的对数似然为$\log p_{\theta}(\x_0)$，下面我们推导其变分下界：
\begin{align}
\begin{split}
    \log p_{\theta}(\x_0) &= \log \int p_{\theta}(\x_0,\cdots,\x_T)d\x_{1:T} \\
    &= \log \int p_{\theta}(\x_0,\cdots,\x_T)\frac{q(\x_1,\cdots,\x_T|\x_0)}{q(\x_1,\cdots,\x_T|\x_0)}d\x_{1:T} \\
    &= \log \int q(\x_1,\cdots,\x_T|\x_0)\frac{p_{\theta}(\x_0,\cdots,\x_T)}{q(\x_1,\cdots,\x_T|\x_0)}d\x_{1:T} \\
    &= \log \E_q \left[\frac{p_{\theta}(\x_0,\cdots,\x_T)}{q(\x_1,\cdots,\x_T|\x_0)}\right] \\
    & \geq \E_q \left[\log \frac{p_{\theta}(\x_0,\cdots,\x_T)}{q(\x_1,\cdots,\x_T|\x_0)}\right].
\end{split}
\label{ddpm:1}
\end{align}
上面最后一个不等式基于的Jensen不等式。此外，由前向和反向过程的马尔可夫性质，即
\begin{align*}
    p_{\theta}(\x_0,\cdots,\x_T) &= p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)\Pi_{t=2}^T p_{\theta}(\x_{t-1}|\x_t) \\
    q(\x_1,\cdots,\x_T|\x_0) &= q(\x_T|\x_{T-1})\Pi_{t=1}^{T-1}q(\x_t|\x_{t-1}),
\end{align*}
我们可以进一步对(\ref{ddpm:1})进行展开，得到：
\begin{align}
\begin{split}
    &\log p_{\theta}(\x_0) \geq \E_q \left[\log \frac{p_{\theta}(\x_0,\cdots,\x_T)}{q(\x_1,\cdots,\x_T|\x_0)}\right] \\
    &= \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)\Pi_{t=2}^T p_{\theta}(\x_{t-1}|\x_t)}{q(\x_T|\x_{T-1})\Pi_{t=1}^{T-1}q(\x_t|\x_{t-1})} \right] \\
    &= \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)\Pi_{t=1}^{T-1} p_{\theta}(\x_{t}|\x_{t+1})}{q(\x_T|\x_{T-1})\Pi_{t=1}^{T-1}q(\x_t|\x_{t-1})} \right] \\
    &= \E_q\left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)}{q(\x_T|\x_{T-1})} \right] + \E_q\left[\log\Pi_{t=1}^{T-1}\frac{p_{\theta}(\x_{t}|\x_{t+1})}{q(\x_t|\x_{t-1})} \right] \\
    &= \E_q[\log p_{\theta}(\x_0|\x_1)] - \E_q[\text{KL}(q(\x_T|\x_{T-1}) \| p_{\theta}(\x_T))] -\Sigma_{t=1}^{T-1}\E_q[\text{KL}(q(\x_t|\x_{t-1}) \| p_{\theta}(\x_{t}|\x_{t+1}))],
\end{split}
\label{ddpm:2}
\end{align}
上面最后一个等式来自于KL散度的定义。此外，由于$p_{\theta}(\x_T)$的计算不需要扩散模型参与，实际上没有可学习参数，所以可以视为一个常数const。最终，我们可以得到如下的变分下界：
\begin{equation}
\log p_{\theta}(\x_0) \geq \E_q[\log p_{\theta}(\x_0|\x_1)]  -\Sigma_{t=1}^{T-1}\E_q[\text{KL}(q(\x_t|\x_{t-1}) \| p_{\theta}(\x_{t}|\x_{t+1}))] + \text{const}
\label{ddpm:3}
\end{equation}

当我们仔细观察上面的$\E_q[\text{KL}(q(\x_t|\x_{t-1}) \| p_{\theta}(\x_{t}|\x_{t+1}))]$项时，会发现该期望计算非常困难。具体来说，我们需要从分布$q(\x_{t-1},\x_{t+1}|\x_0)$中采样$\x_{t-1}$和$\x_{t+1}$来计算期望，而该分布的具体形式未知。

为了解决这个问题，我们可以使用若干由$q$函数定义的前向转移函数\emph{模拟出}一个反向转移函数来替代$q(\x_t|\x_{t-1})$，这个新的反向转移函数具有和$p_{\theta}(\x_t|\x_{t+1})$都是反向的，所以期望的计算可以大大简化。具体地，我们由Bayes定理，可得：
\begin{equation*}
    q(\x_t|\x_{t-1})=\frac{q(\x_{t-1}|\x_t)q(\x_t)}{q(\x_{t-1})},
\end{equation*}
又因为$\x_{t-1}$实际上是前向过程中由$\x_0$产生的，所以$\x_{t-1}$的分布依赖于$\x_0$，故我们将上式替换成下面的基于$\x_0$的形式：
\begin{equation}
    q(\x_t|\x_{t-1},\x_0)=\frac{q(\x_{t-1}|\x_t,\x_0)q(\x_t|\x_0)}{q(\x_{t-1}|\x_0)},
\label{ddpm:bayes}
\end{equation}
此时，我们可以根据(\ref{ddpm:1})推导出$\log p_{\theta}(\x_0)$的新变分下界如下：
\begin{align}
\begin{split}
    \log p_{\theta}(\x_0) & \geq \E_q \left[\log \frac{p_{\theta}(\x_0,\cdots,\x_T)}{q(\x_1,\cdots,\x_T|\x_0)}\right] \\
    &= \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)\Pi_{t=2}^T p_{\theta}(\x_{t-1}|\x_t)}{q(\x_1|\x_0)\Pi_{t=2}^T q(\x_t|\x_{t-1},\x_0)} \right] \\
    &= \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)}{q(\x_1|\x_0)} \right] + \E_q \left[\log \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_t|\x_{t-1},\x_0)} \right].
\end{split}
\label{ddpm:3}
\end{align}

随后，我们将(\ref{ddpm:bayes})代入(\ref{ddpm:3})的第二项，可得：
\begin{align}
\begin{split}
    \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_t|\x_{t-1},\x_0)} &= \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{\frac{q(\x_{t-1}|\x_t,\x_0)q(\x_t|\x_0)}{q(\x_{t-1}|\x_0)}} \\
    &= \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_{t-1}|\x_t,\x_0)}  \times \Pi_{t=2}^T \frac{q(\x_{t-1}|\x_0)}{q(\x_t|\x_0)} \\
    &= \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_{t-1}|\x_t,\x_0)}  \times \frac{q(\x_1|\x_0)}{q(\x_T|\x_0)},
\end{split}
\label{ddpm:4}
\end{align}
其中最后一个等式成立是因为对任意序列$a_1,a_2,\cdots,a_T$，有$\Pi_{t=2}^T\frac{a_{t-1}}{a_t}=\frac{a_1}{a_2}\times\frac{a_2}{a_3}\times\cdots\times\frac{a_{T-1}}{a_T}=\frac{a_1}{a_T}$。随后我们将(\ref{ddpm:4})代入(\ref{ddpm:3})中，可得：
\begin{align}
\begin{split}
    & \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)}{q(\x_1|\x_0)} \right] + \E_q \left[\log \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_t|\x_{t-1},\x_0)} \right] \\
    &= \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)}{q(\x_1|\x_0)} \right] + \E_q \left[\log \left(\Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_{t-1}|\x_t,\x_0)}  \times \frac{q(\x_1|\x_0)}{q(\x_T|\x_0)}\right) \right] \\
    &=\E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)}{q(\x_1|\x_0)} + \log \frac{q(\x_1|\x_0)}{q(\x_T|\x_0)} \right] + \E_q \left[\log \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_{t-1}|\x_t,\x_0)}  \right] \\
    &= \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)}{q(\x_T|\x_0)} \right] + \E_q \left[\log \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_{t-1}|\x_t,\x_0)}  \right] \\
    &= \E_q [p_{\theta}(\x_0|\x_1)] + \E_q\left[\frac{p_{\theta}(\x_T)}{q(\x_T|\x_0)}\right] + \Sigma_{t=2}^T \E_q \log \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_{t-1}|\x_t,\x_0)} \\
    &= \E_q [p_{\theta}(\x_0|\x_1)] -\text{KL}(q(\x_T|\x_0)\| p_{\theta}(\x_T)) -  \Sigma_{t=2}^T \text{KL}(q(\x_{t-1}|\x_t,\x_0) \| p_{\theta}(\x_{t-1}|\x_t)),
\end{split}
\label{ddpm:5}
\end{align}
其中我们在最后一个等式中使用了KL散度的定义。由于上式中$p_{\theta}(\x_T)$不需要学习，所以$\text{KL}(q(\x_T|\x_0)\| p_{\theta}(\x_T))$可以视作常数，因此，我们可以得到下面的数据对数似然$\log p_{\theta}(\x_0)$的变分下界：
\begin{equation}
\log p_{\theta}(\x_0) \geq \E_q [\log p_{\theta}(\x_0|\x_1)] -  \Sigma_{t=2}^T \text{KL}(q(\x_{t-1}|\x_t,\x_0) \| p_{\theta}(\x_{t-1}|\x_t)) + \text{const}.
\label{ddpm:elbo}
\end{equation}
可以看出，计算(\ref{ddpm:elbo})中的KL项（本质上是期望）所需的$\x_t$和$\x_0$实际上可以从分布$q(\x_t|\x_0)$中采样得到，该分布具有简洁的形式，因此(\ref{ddpm:elbo})相比前面提到的(\ref{ddpm:3})计算上简单很多。于是我们可以定义\emph{变分下界损失}$\mathcal{L}_{\text{VLB}}$如下：
\begin{equation}
\mathcal{L}_{\text{VLB}} := -\E_q [\log p_{\theta}(\x_0|\x_1)] +  \Sigma_{t=2}^T \text{KL}(q(\x_{t-1}|\x_t,\x_0) \| p_{\theta}(\x_{t-1}|\x_t)),
\label{ddpm:loss_vlb}
\end{equation}
可以看出，最小化$\mathcal{L}_{\text{VLB}}$即是最大化(\ref{ddpm:elbo})中的变分下界，等价于最大化扩散模型生成数据的似然。


下一步我们要确定$q(\x_{t-1}|\x_t,\x_0)$的具体形式。由(\ref{ddpm:bayes})可知，$q(\x_{t-1}|\x_t,\x_0)$由$q(\x_{t}|\x_{t-1},\x_0)$、$q(\x_{t-1}|\x_0)$和$q(\x_{t}|\x_0)$决定，而由扩散模型前向过程的定义可知，这三项的表达式分别为：
\begin{align*}
    q(\x_{t}|\x_{t-1},\x_0) &= \N(\x_t|\sqrt{\alpha_t}\x_{t-1},(1-\alpha_t)\mathbf{I}),  \\
    q(\x_{t-1}|\x_0) &= \N(\x_{t-1}|\sqrt{\bar{\alpha}_{t-1}}\x_0,(1-\bar{\alpha}_{t-1})\mathbf{I}), \\
    q(\x_{t}|\x_0) &=\N(\x_{t}|\sqrt{\bar{\alpha}_{t}}\x_0,(1-\bar{\alpha}_{t})\mathbf{I}),
\end{align*}
所以，由(\ref{ddpm:bayes})，我们可以得到
\begin{equation*}
    q(\x_{t-1}|\x_t,\x_0) = \frac{\N(\x_t|\sqrt{\alpha_t}\x_{t-1},(1-\alpha_t)\mathbf{I})\N(\x_{t-1}|\sqrt{\bar{\alpha}_{t-1}}\x_0,(1-\bar{\alpha}_{t-1})\mathbf{I})}{\N(\x_{t}|\sqrt{\bar{\alpha}_{t}}\x_0,(1-\bar{\alpha}_{t})\mathbf{I})}.
\label{ddpm:dist_of_reverse_pre}
\end{equation*}

随后，我们实际上可以证明$q(\x_{t-1}|\x_t,\x_0)$也服从高斯分布，并具有$\N(\x_{t-1}|\A\x_t+\B\x_0,\C\mathbf{I})$的形式，为了确认$\A$，$\B$和$\C$的具体形式，我们可以首先将$\ref{ddpm:dist_of_reverse_pre}$中右侧三个高斯分布的乘积转化为指数之和，随后可以通过求一次导和二次导得到$\A$，$\B$和$\C$。这里我们暂时忽略具体过程，$q(\x_{t-1}|\x_t,\x_0)$的最后形式如下：
\begin{align}
\begin{split}
    q(\x_{t-1}|\x_t,\x_0) &= \N(\x_{t-1}|\mu_q(\x_t,\x_0),\Sigma_q(t)),\\
    \mu_q(\x_t,\x_0) &= \frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}}{1-\bar{\alpha}_t}\x_t + \frac{(1-\alpha_t)\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_t}\x_0 \\
    \Sigma_q(t) &= \frac{(1-\alpha_t)(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{I}  \stackrel{\text{def}}{=} \sigma_q^2(t)\mathbf{I},
\end{split}
\label{ddpm:dist_of_reverse}
\end{align}
其中$\bar{\alpha}_t=\Pi_{i=1}^t \alpha_i$。

现在我们已经得到了变分下界(\ref{ddpm:elbo})中$q(\x_{t-1}|\x_t,\x_0)$所具有的高斯形式，由于$p_{\theta}(\x_{t-1}|\x_t)$是可以设计的，所以我们选择将其也设置为一个高斯分布，因为两个高斯分布的KL散度是便于简化计算的。具体地，我们定义：
\begin{equation}
p_{\theta}(\x_{t-1}|\x_t) = \N(\x_{t-1}| \mu_{\theta}(\x_t,t), \sigma_q^2(t)\mathbf{I}),
\label{ddpm:p_reverse}
\end{equation}
其中均值向量$\mu_{\theta}(\x_t,t)$是由一个神经网络生成的，其具体形式我们将在后文中给出；至于方差，我们则是选择了与(\ref{ddpm:dist_of_reverse})中$q(\x_{t-1}|\x_t,\x_0)$相同的$\sigma_q^2(t)\mathbf{I}$。于是(\ref{ddpm:elbo})中的KL散度可以简化为
\begin{align}
\begin{split}
    & \text{KL}\left(q(\x_{t-1}|\x_t,\x_0) \| p_{\theta}(\x_{t-1}|\x_t)\right) \\
    &= \text{KL} \left(\N(\x_{t-1}|\mu_q(\x_t,\x_0),\sigma_q^2(t)\mathbf{I}) \| \N(\x_{t-1}| \mu_{\theta}(\x_t,t), \sigma_q^2(t)\mathbf{I})\right) \\
    &= \frac{1}{2\sigma_q^2(t)} \| \mu_q(\x_t,\x_0) - \mu_{\theta}(\x_t,t) \|^2,
\label{ddpm:elbo_simp_1}
\end{split}
\end{align}
在上面的推导中，我们使用了两个方差相同的高斯分布的KL散度实际上是这两个分布均值向量的欧式距离这一关系。

此外，对于变分下界(\ref{ddpm:elbo})中的$\log p_{\theta}(\x_0|\x_1)$可以进行如下简化：
\begin{align}
\begin{split}
\log p_{\theta}(\x_0|\x_1) &= \log \N(\x_0| \mu_{\theta}(\x_1,1),\sigma_q^2(1)\mathbf{I}) \\
&= \log \left( \frac{1}{\left(\sqrt{2\pi\sigma_q^2(1)} \right)^d} \right)\exp \left\{-\frac{\|\x_0 -\mu_{\theta}(\x_1,1) \|^2}{2\sigma_q^2(1)} \right\} \\
&= -\frac{\|\x_0 -\mu_{\theta}(\x_1,1) \|^2}{2\sigma_q^2(1)} -\frac{d}{2}\log (2\pi\sigma_q^2(1)),
\label{ddpm:elbo_simp_2}
\end{split}
\end{align}
可以看出(\ref{ddpm:elbo_simp_1})和(\ref{ddpm:elbo_simp_2})从优化目标上实际上是统一的，都是\emph{最小化前向过程产生的数据轨迹和对应的反向过程生成的数据轨迹的欧式距离}。

下面，我们在对$\mu_q(\x_t,\x_0)$的具体形式进行分析，并由此设计$\mu_{\theta}(\x_t,t)$的计算方式，最后完成DDPM目标函数的推导。我们由$q(\x_t|\x_0)$的表达式可知：
\begin{equation*}
    \x_t =\sqrt{\bar{\alpha}_t}\x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon \Rightarrow  \x_0 =\frac{\x_t - \sqrt{1-\bar{\alpha}_t}\epsilon}{\sqrt{\bar{\alpha}_t}}.
\end{equation*}
随后我们将上式代入(\ref{ddpm:dist_of_reverse})中$\mu_q(\x_t,\x_0)$的表达式，可以得到：
\begin{align}
\begin{split}
    \mu_q(\x_t,\x_0) &= \frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\x_t +(1-\alpha_t)\sqrt{\bar{\alpha}_{t-1}}\x_0 }{1-\bar{\alpha}_t} \\
    &= \frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\x_t +(1-\alpha_t)\sqrt{\bar{\alpha}_{t-1}}\frac{\x_t - \sqrt{1-\bar{\alpha}_t}\epsilon}{\sqrt{\bar{\alpha}_t}} }{1-\bar{\alpha}_t}\\
    &= \frac{1}{\sqrt{\alpha_t}}\x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}\sqrt{\alpha_t}}\epsilon,
\end{split}
\label{ddpm:mu_q}
\end{align}
上式实际上将$\mu_q(\x_t,\x_0)$由关于$\x_0$的函数转化成关于高斯噪声$\epsilon$的函数。

下面我们将设计一个更合适的$\mu_{\theta}(\x_t,t)$的形式，使之适配$\mu_q(\x_t,\x_0)$的表达式，具体地，我们进行如下设计：
\begin{equation}
\mu_{\theta}(\x_t,t)=\frac{1}{\sqrt{\alpha_t}}\x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}\sqrt{\alpha_t}}\epsilon_{\theta}(\x_t,t),
\label{ddpm:mu_theta}
\end{equation}
值得注意的是，我们此时让模型预测第$t$步中向$\x_t$中加入的噪声，即$\epsilon_{\theta}(\x_t,t)$。

最后，我们将(\ref{ddpm:elbo_simp_1})、(\ref{ddpm:elbo_simp_2})、(\ref{ddpm:mu_q})和(\ref{ddpm:mu_theta})代入(\ref{ddpm:elbo})，并结合(\ref{ddpm:loss_vlb})的定义，可得：
\begin{equation}
\mathcal{L}_{\text{VLB}} = -\sum_{t=1}^T \E_q \left[\frac{1}{2\sigma_q^2(t)}\frac{(1-\alpha_t)^2}{(1-\bar{\alpha}_t)\alpha_t}\|\epsilon_{\theta}(\x_t,t)-\epsilon \|^2 \right],
\label{ddpm:loss_vlb_denoise}
\end{equation}
于是我们最终得到了DDPM的目标函数，它实际上是一个监督学习型的目标函数，即训练扩散模型的输出，即$\epsilon(\x_t,t)$，来预测前向过程中每一步加入的噪声$\epsilon$。注意，实际上加入的噪声是$\epsilon$乘上某系数，但我们设计扩散模型反向过程中也让$\epsilon(\x_t,t)$乘上此系数，所以在(\ref{ddpm:loss_vlb_denoise})中该系数可以被提取出来，形成系数$\frac{1}{2\sigma_q^2(t)}\frac{(1-\alpha_t)^2}{(1-\bar{\alpha}_t)\alpha_t}$。

最后我们介绍扩散模型的生成过程。在训练结束后，我们可以获得神经网络$\epsilon_{\theta}(\x_t,t)$。生成新样本时，我们先采样一个高斯白噪声$\x_T\sim\N(\mathbf{0},\mathbf{I})$，随后便可以利用(\ref{ddpm:p_reverse})中建立的$\x_{t-1}$与$\x_t$的关系以及(\ref{ddpm:mu_theta})中$\mu_\theta$的定义，迭代式地生成$\x_{T-1},\cdots,\x_0$，具体的计算方式为：
\begin{equation*}
    \x_{t-1} = \frac{1}{\sqrt{\alpha_t}}\left(\x_t -\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon(\x_t,t) \right) + \sigma_q(t)\z,\quad \z\sim\N(\mathbf{0},\mathbf{I}).
\end{equation*}

\subsection{基于分数的生成模型 (SGM)}

基于分数的生成模型的核心是Stein分数函数（简称分数函数）\cite{Hyvrinen2005EstimationON}。给定一个样本概率密度函数$p(\x)$，其分数函数被定义为对数概率密度的梯度：
\begin{equation*}
    \s_\theta(\x) := \nabla_{\x}\log p(\x).
\end{equation*}
注意不同于统计领域常见的Fisher分数$\nabla_\theta \log p_{\theta}(\x)$，Stein分数是关于\emph{样本}的梯度，而不是关于模型参数$\theta$的梯度。该分数函数实际上是数据分布的梯度场，它指向使数据出现概率增加最快的方向。

当我们获得分数函数$\nabla_{\x}\log p(\x)$后，便可以通过朗之万动力学（Langevin dynamics）来从概率分布$p(\x)$中采样。具体地，给定一个固定的步长$\alpha>0$以及一个初始值$\tilde{\x}_0\sim\pi(\x)$（$\pi(\x)$是某个先验分布），朗之万方法通过下面的方式进行迭代更新采样：
\begin{equation*}
    \tilde{\x}_t = \tilde{\x}_{t-1} + \frac{\alpha}{2} \nabla_{\x}\log p(\tilde{\x}_{t-1}) + \sqrt{\alpha}\epsilon_t,\quad \epsilon_t\sim\N(\mathbf{0},\mathbf{I}).
\end{equation*}
当某些正则性条件被满足时，若$\alpha\rightarrow 0$且$T\rightarrow \infty$，\cite{max2011bayesian}说明$\tilde{\x}_T$的分布与$p(\x)$相同。当$\alpha> 0$且$T< \infty$时上面的公式存在一些误差，需要用Metropolis-Hastings更新来修正，但在实践中通常可以忽略这种修正\cite{du2019implicit,nijkamp2019anatomy}。在本文中，当$\alpha$很小且$T$很大时，我们假设这种误差是可以忽略的。综上所述，我们知道只要能学到分数函数，便可以通过朗之万方法从原始数据分布中采样，这就是基于分数的生成模型的核心思想。

前人提出了多种方法来学习分数函数。一种方法称为显式分数函数匹配（Explicit Score Matching，ESM）\cite{vincent2011connection}。假设我们有一个包含$M$个样本的数据集$\X=\{\x^{(1)},\cdots,\x^{(M)}\}$，那么我们可以通过核密度估计来近似真实数据分布$p(\x)$：
\begin{equation*}
    q_h(\x)=\frac{1}{M}\sum_{m=1}^M \frac{1}{h} K\left(\frac{\x-\x^{(m)}}{h} \right),
\end{equation*}
其中$K(\cdot)$是核函数，$h$是核函数的超参数。随后显式分数函数匹配基于$q_h(\x)$来学习分数函数$\s_\theta(\x)$，目标函数如下：
\begin{equation*}
    \mathcal{L}_{\text{ESM}}:=\frac{1}{2}\E_{p(\x)} \|\s_\theta(\x)-\nabla_{\x}\log p(\x) \|^2 \approx \frac{1}{2}\E_{q_h(\x)} \| s_\theta(\x)-\nabla_{\x}\log q_h(\x)\|^2.
\end{equation*}
该方法的主要问题在于核密度是非参数化的、它对真实分布的近似能力很有限，尤其是当样本数量有限或数据处于高维空间时，核密度估计的效果会较差。

为了避免近似真实数据分布，\cite{Hyvrinen2005EstimationON}提出了隐式分数函数匹配（Implicit Score Matching，ISM），其目标函数为：
\begin{equation*}
    \mathcal{L}_{\text{ISM}}:=\E_{p(\x)} \left[\text{Tr}(\nabla_{\x} \s_\theta (\x)) + \frac{1}{2}\|\s_\theta (\x) \|^2 \right],
\end{equation*}
其中$\nabla_{\x} \s_\theta (\x)$表示$\s_\theta (\x)$的Jacobian。尽管该方法避免了直接近似真实数据分布$p(\x)$，但\cite{song2019generative}指出该目标函数的迹函数难以计算，导致该方法缺乏可扩展性。

现在最流行的分数函数学习方法是基于去噪分数函数匹配（Denoising Score Matching，DSM）\cite{vincent2011connection}。给定一个样本$\x_0$，该方法使用一个预定义的噪声分布$q_\sigma(\x^\prime|\x)$对其进行扰动得到带噪声数据，其分布为$q_\sigma(\x^\prime):=\int q_\sigma(\x^\prime|\x)p(\x)d\x$。DSM的核心思想是使用分数函数匹配来估计\emph{该带噪声数据分布$q_\sigma(\x^\prime)$的分数函数}，优化目标如下：
\begin{equation}
\E_{q_\sigma(\x^\prime|\x)p(\x)} \left[\frac{1}{2}\| \s_{\theta}(\x^\prime) - \nabla_{\x^\prime}\log q(\x^\prime|\x) \|^2 \right].
\label{sgm:dsm}
\end{equation}
\cite{vincent2011connection}的结论显示最小化以上目标函数得到的最优分数函数（记为$\s_{\theta^*}(\x)$）\emph{几乎必然满足}$\s_{\theta^*}(\x)=\nabla_\x\log q_\sigma(\x)$。值得注意的是，只有当噪声足够小时，才有$q_\sigma(\x)\approx p(\x)$成立。

为了高效地计算(\ref{sgm:dsm})，一般可以设置$q(\x^\prime|\x)=\N(\x^\prime|\x,\sigma^2)$，即让$\x^\prime=\x+\sigma\epsilon,\epsilon\sim\N(\mathbf{0},\mathbf{I})$。此时我们有：
\begin{align*}
    \nabla_{\x^\prime}\log q(\x^\prime|\x) &= \nabla_{\x^\prime}\log \frac{1}{(\sqrt{2\pi\sigma^2})^d}\exp\left\{-\frac{\|\x^\prime-\x \|^2}{2\sigma^2}\right\} \\
    &= \nabla_{\x^\prime} \left\{ -\frac{\|\x^\prime-\x \|^2}{2\sigma^2} -\frac{d}{2}\log (2\pi\sigma^2) \right\} = -\frac{\x^\prime-\x}{\sigma^2}=-\frac{\epsilon}{\sigma}.
\end{align*}

于是(\ref{sgm:dsm})中的目标函数变成：
\begin{equation}
\E_{q_\sigma(\x^\prime|\x)p(\x)} \left[\frac{1}{2}\| \s_{\theta}(\x^\prime) - \nabla_{\x^\prime}\log q(\x^\prime|\x)  \|^2 \right] = \E_{q(\x^\prime)} \left[ \frac{1}{2}\left\| \s_\theta(\x +\sigma\epsilon)+\frac{\epsilon}{\sigma} \right\|^2\right].
\label{sgm:dsm_obj}
\end{equation}
可以看出，上面的目标函数的作用，就是训练分数函数$\s_\theta$，让其预测输入样本中的噪声（乘上系数$-1/\sigma^2$）。从本质上看，\emph{去除样本中的噪声即等价于让样本朝分布中高概率区域移动}，这正是分数函数的定义。

尽管目标函数(\ref{sgm:dsm_obj})简洁且方便计算优化，但\cite{song2019generative}指出由于真实世界数据常呈现低维流形分布，所以分数函数在一些区域可能无定义；此外低密度区域的数据少，导致该区域的分数函数难以准确估计。为了应对这两个挑战，\cite{song2019generative}提出NCSN（Noise Conditional Score Network）方法采用不同尺度的随机高斯噪声对数据进行扰动。具体地，令$\sigma_1 > \sigma_2 > \cdots > \sigma_i > \cdots > \sigma_L > 0$是从大到小$L$个不同的尺度，并利用
\begin{equation}
    q(\x^\prime|\x_0)=\N(\x^\prime|\x_0,\sigma_i^2\mathbf{I}),
\label{sgm:ncsn_forward}
\end{equation}
即$\x^\prime=\x_0+\sigma_i\epsilon$来生成一系列具有不同噪声尺度的带噪样本。此时的目标变成：
\begin{align}
\begin{split}
    \mathcal{L}_{\text{NCSN}}=\E_{i\in\{1,\cdots,L\},q(\x^\prime|\x_0)p(\x_0)} \left[\frac{1}{2} \lambda(\sigma_i)\left\| \s_\theta(\x^\prime,\sigma_i) + \frac{\epsilon}{\sigma_i} \right\|^2 \right],
\end{split}
\label{sgm:ncsn}
\end{align}
其中$\lambda(\sigma_i)$是一个取决于$\sigma_i$的权重系数，其目的是为了让不同损失项的量级不因$\sigma_i$的变化而变化，\cite{song2019generative}提出一种选择是让$\lambda(\sigma)=\sigma^2$。现在的分数函数为$\s_\theta(\x^\prime,\sigma_i)$，即我们输入带噪声的样本以及噪声尺度，输出该样本处的分数。从直观上看，通过在数据上施加不同尺度的高斯噪声，一方面使得扰动后的数据不再局限于低维流形，保证了分数函数估计在全空间上有定义，另一方面大尺度高斯噪声能有效填充数据分布中的低密度区域，为分数函数提供更多训练信号以提升估计精度。

在$\s_\theta(\x,\sigma)$完成后，NCSN提出使用退火朗之万动力学（Annealed Langevin dynamics）来采样生成样本，其数学描述如下：
\begin{align}
\begin{split}
\alpha_i &\leftarrow \frac{\sigma_i^2}{\sigma_L^2}\alpha, \\
\x^\prime_t & \leftarrow\x^\prime_{t-1} + \frac{\alpha_i}{2}\s_{\theta}(\x^\prime_{t-1},\sigma_i) + \sqrt{\alpha_i}\epsilon,\ \epsilon\sim\N(\mathbf{0},\mathbf{I}),
\end{split}
\label{sgm:annealed_langevin}
\end{align}
退火朗之万动力学从$1$到$L$依次选择每个噪声尺度，利用(\ref{sgm:annealed_langevin})中第一行设置与噪声尺度的平方成正比的步长$\alpha_i$；对每个噪声尺度，利用(\ref{sgm:annealed_langevin})中第二行进行若干轮迭代式采样。与使用单一噪声的朗之万动力学不同，退火朗之万动力学在采样中逐渐降低噪声尺度。\cite{song2019generative}指出通过这种方式，可以迫使采样过程跨过低维流形之间的低密度区域，产生更符合真实数据分布的样本。

当我们比较DDPM的目标函数(\ref{ddpm:loss_vlb_denoise})和SGM的目标函数(\ref{sgm:ncsn})时，我们可以发现实际上当设置DDPM中的$\epsilon_{\theta}(\x,t)$和SGM中的$\s_\theta(\x,\sigma)$在功能上是一致的，在输出上也仅相差一个常系数。我们将在下一节从另一个视角揭示这两大类方法的内在联系。


\subsection{随机微分方程 (Score SDE)}

之前我们介绍的DDPM和SGM都是利用离散时间上的迭代关系式来刻画相邻时刻两个变量间的关系，实际上通过一些连续化技术和公式变化，它们都可以与连续时间上的微分方程（Differential Equation）建立联系。我们在本节首先介绍微分方程（包含常微分方程和随机微分方程）的定义，随后给出DDPM和SGM的随机微分方程形式表示。

我们首先介绍常微分方程（Ordinary Differential Equation，ODE）和随机微分方程（Stochastic Differential Equation，SDE）的概念。我们先介绍ODE，一阶（first-order）ODE的数学表示如下：
\begin{equation*}
    \frac{d\x(t)}{dt}=\f(t,\x),
\end{equation*}
其中$\f(t,\x)$是关于$t$和$\x$的函数。在后文中，我们主要使用ODE的微分形式（differential form）：
\begin{equation*}
    d\x=\f(t,\x)dt.
\end{equation*}

SDE相比ODE多了一项刻画\emph{随机扰动}的项，具体地，其表达式如下：
\begin{equation*}
    \frac{d\x(t)}{dt}=\f(t,\x) + \mathbf{g}(t,\x)\xi(t),\ \text{where}\ \xi(t)\sim\N(\mathbf{0},\mathbf{I}),
\end{equation*}
其中$\xi(t)$刻画了时间$t$的随机性。SDE的微分形式可以写成：
\begin{equation*}
    d\x=\f(t,\x)dt + \mathbf{g}(t,\x)d\w,
\end{equation*}
上面的$d\w=\xi(t)dt$是布朗运动（Brownian motion）的微分形式。

下面我们介绍SDE视角下DDPM和SGM的前向与反向过程。我们首先分别定义通用的前向和反向过程的微分形式SDE，随后介绍DDPM和SGM具体对应的SDE。具体地，刻画前向过程的微分形式SDE如下：
\begin{equation}
    d\x=\underbrace{\f(t,\x)}_{\text{漂移项}}dt + \underbrace{g(t)}_{\text{扩散项}}d\w,
\label{sde:forward}
\end{equation}
其中$\xi(t)$对于所有时刻$t$均为独立同分布的高斯随机变量，$d\w=\xi(t)dt$是布朗运动的微分形式，直观上看，$\xi(t)$可以看成关于时间$t$的变化率，通过对$\xi(t)dt$进行积分即可得到$d\w$。函数$\f(t,\x)$和$g(t)$具有明确的物理含义，前者称为\emph{漂移项}，它定义了在封闭系统中，分子在没有随机效应时的确定性运动方式；后者称为\emph{扩散项}，它描述了分子如何通过布朗运动随机地从一个位置跃迁到另一个位置，该函数决定了随机运动的强度参数。

扩散模型的反向过程对应于在时间上反向演化，根据Anderson\cite{anderson1982reverse}的结论，(\ref{sde:forward})的反向时间SDE表述如下：
\begin{equation}
    d\x= [\underbrace{\f(t,\x)}_{\text{漂移项}} - g(t)^2 \underbrace{\nabla_\x \log p_t(\x)}_{\text{分数函数}} ]dt + \underbrace{g(t)d\bar{\w}}_{\text{反向时间扩散项}},
\label{sde:backward}
\end{equation}
其中$p_t(\x)$是$t$时刻$\x$的概率分布，$\bar{\w}$是时间反向演化时的维纳过程（Wiener process）。

Song等人\cite{song2019generative}证明了下面被称为概率流（probability flow）ODE的轨迹与反向时间SDE具有相同的边际分布，其形式如下：
\begin{equation}
    d\x= \left[\f(t,\x) -\frac{1}{2} g(t)^2\nabla_\x \log p_t(\x)\right]dt.
\label{ode:backward}
\end{equation}
反向时间SDE和概率流ODE都可以从同一数据分布中进行采样，因为它们的轨迹具有相同的边际分布特征。下面我们介绍DDPM和SGM的前向和反向SDE形式，概率流ODE形式由此可以很容易地推出（因为其由和反向时间SDE相同的$\f(t,\x)$，$g(t)$和$\nabla_\x\log p_t(\x)$定义），所以我们不展开阐述。

下面我们结合(\ref{sde:forward})和(\ref{sde:backward})，给出DDPM和SGM前向和反向过程的SDE表达。首先由(\ref{ddpm:forward_process})中定义的DDPM前向过程的转移核$q(\x_t|\x_{t-1})$可知：
\begin{equation*}
    \x_i = \sqrt{1-\beta_i}\x_{i-1} + \sqrt{\beta_i}\z_{i-1},\ \z_{i-1}\sim\N(\mathbf{0},\mathbf{I}).
\end{equation*}

为了获得其对应的SDE表示，我们进行下面一系列设置。首先，我们将$\x_i,\x_{i-1},\z_i,\z_{i-1}$和$\beta_i$分别看成关于连续时间的函数，即
\begin{equation*}
    \x_i=\x(t+\Delta t),\ \x_{i-1}=\x(t),\ \z_i=\z(t+\Delta t),\ \z_{i-1}=\z(t),\ \beta_i = \beta(t+\Delta t)\Delta t,
\end{equation*}
其中$\Delta t$表示步长，$\beta(t+\Delta t)$是与噪声调度有关的系数。根据这些函数，我们可以推导DDPM的前向过程的SDE如下：
\begin{align*}
\begin{split}
     \x_i &= \sqrt{1-\beta_i}\x_{i-1} + \sqrt{\beta_i}\z_{i-1} \\
    \Rightarrow\quad  \x(t+\Delta t) &= \sqrt{1-\beta(t+\Delta t)\Delta t}\ \x(t) + \sqrt{ \beta(t+\Delta t)\Delta t}\ \z(t) \\
    \Rightarrow\quad \x(t+\Delta t) &\approx \left(1- \frac{1}{2}\beta(t+\Delta t)\Delta t\right)\ \x(t) + \sqrt{ \beta(t+\Delta t)\Delta t}\ \z(t) \\
    \Rightarrow\quad \x(t+\Delta t) &\approx \x(t) - \frac{1}{2}\beta(t)\Delta t\ \x(t) + \sqrt{ \beta(t)\Delta t}\ \z(t),
\end{split}
\end{align*}
所以，当$\Delta t\rightarrow 0$时，我们便得到了DDPM前向过程的SDE的表达式：
\begin{equation}
    d\x = -\frac{1}{2}\beta(t)\x dt + \sqrt{\beta(t)}d\w.
\label{sde:ddpm_forward}
\end{equation}

对比(\ref{sde:ddpm_forward})和(\ref{sde:forward})，我们可以发现DDPM中，$\f(t,\x)=-\frac{1}{2}\beta(t)\x$，$g(t)=\sqrt{\beta_t}$，将这两个函数的表达式代入(\ref{sde:backward})，我们便可以得到DDPM反向过程的SDE表示：
\begin{align}
\begin{split}
    d\x &= \left[-\frac{1}{2}\beta(t)\x -\beta(t) \nabla_\x \log p_t(\x) \right] dt + \sqrt{\beta_t} d\bar{\w} \\
    &= -\beta(t) \left[\frac{\x}{2} + \nabla_\x \log p_t(\x) \right]dt + \sqrt{\beta_t} d\bar{\w}.
\end{split} 
\label{sde:ddpm_backward}
\end{align}

下面我们介绍SGM的前向和反向过程对应的SDE，这里我们关注重要的NCSN方法\cite{song2020score}，它使用不同的尺度的噪声生成一系列带噪声样本。由于NCSN使用退火朗之万动力学，即在反向生成过程中逐渐降低噪声，所以在前向过程中，我们可以设噪声逐渐增大。假设一共有$L$个不同的噪声尺度，记为$\sigma_1 > \sigma_2 > \cdots > \sigma_L > 0$。NCSN按照(\ref{sgm:ncsn_forward}在不同时刻向原始样本$\x_0$加入不同尺度的噪声，所以我们有：
\begin{equation*}
    p(\x_i|\x_0) =\N(\x_i|\x_0,\sigma_i^2),\ p(\x_{i-1}|\x_0) =\N(\x_{i-1}|\x_0,\sigma_{i-1}^2).
\end{equation*}
下面我们建立$\x_i$与$\x_{i-1}$间的关系，首先这两个变量的均值相同，故它们之间的差值是一个均值为$\mathbf{0}$的高斯变量，记为$\u$，故有$\x_i=\x_{i-1}+\u$。此外，注意到$\x_{i-1}$和$\u$相互独立，故$\text{Var}[\x_i]=\text{Var}[\x_{i-1}]+\text{Var}[\u]$，所以有$\text{Var}[\u]=\text{Var}[\x_i]-\text{Var}[\x_{i-1}]=\sigma_i^2-\sigma_{i-1}^2$。综上所述，我们有：
\begin{equation*}
    \x_i = \x_{i-1} + \sqrt{\sigma_i^2-\sigma_{i-1}^2} \z_{i-1},\ i=1,2,\cdots,L.
\end{equation*}

下面我们根据上式推导NCSN前向过程的SDE形式。针对$\x_i,\x_{i-1},\z_{i-1}$和$\sigma_i,\sigma_{i-1}$，我们使用与DDPM前向过程的SDE推导相同的连续函数形式，即
\begin{equation*}
    \x_i=\x(t+\Delta t),\ \x_{i-1}=\x(t),\ \z_{i-1}=\z(t),\ \sigma_i = \sigma(t+\Delta t),\ \sigma_{i-1} = \sigma(t),
\end{equation*}
其中$\Delta t$表示步长。于是我们有：
\begin{align*}
    \x_i &= \x_{i-1} + \sqrt{\sigma_i^2-\sigma_{i-1}^2}\ \z_{i-1} \\
    \Rightarrow\quad \x(t+\Delta t) &=\x(t) + \sqrt{\sigma(t+\Delta t) -\sigma(t)}\ \z(t) \\
    \Rightarrow\quad \x(t+\Delta t) &\approx \x(t) + \sqrt{\frac{d[\sigma(t)]^2}{dt}\Delta t}\ \z(t).
\end{align*}
所以，当$\Delta t\rightarrow 0$时，我们便得到了SGM前向过程的SDE的表达式：
\begin{equation}
    d\x = \sqrt{\frac{d[\sigma(t)]^2}{dt}}d\w.
\label{sde:sgm_forward}
\end{equation}
对比(\ref{sde:sgm_forward})和(\ref{sde:forward})，我们可以发现SGM中，$\f(t,\x)=0$，$g(t)=\sqrt{\frac{d[\sigma(t)]^2}{dt}}$，将这两个函数的表达式代入(\ref{sde:backward})，我们便可以得到DDPM反向过程的SDE表示：
\begin{align}
\begin{split}
    d\x &= [\f(t,\x) - g(t)^2 \nabla_\x \log p_t(\x) ]dt + g(t)d\bar{\w} \\
    &= -\left(\frac{d[\sigma(t)]^2}{dt} \nabla_\x \log p_t(\x) \right)dt + \sqrt{\frac{d[\sigma(t)]^2}{dt}} d\bar{\w}.
\end{split} 
\label{sde:sgm_backward}
\end{align}

一旦我们能学到每个时刻$t$的分数函数$\nabla_\x\log p_t(\x)$，那么我们便可以由(\ref{sde:ddpm_backward})和(\ref{sde:sgm_backward})得到DDPM和SGM反向过程SDE或概率流ODE，并利用通过多种优化技术来求解它们以迭代式地生成样本。一般的SDE或ODE难有解析解，所以人们一般用数值方法求解，例如退火朗之万动力学\cite{song2019generative}、数值SDE求解器\cite{jolicoeur2021gotta,song2020score}、数值ODE求解器\cite{karras2022elucidating,lu2022dpm,song2020denoising,song2020score}以及预测器-校正器（predictor-corrector）方法（基于马尔可夫链的解析解与数值ODE/SDE求解器的数值解相结合）\cite{song2020score}。我们这里不再介绍这些技术的细节，感兴趣的读者可以参考相关文献。

\subsection{条件生成的核心方法}

在扩散模型中实现条件生成的核心挑战在于如何将外部信息（如文本、类别标签等）有效融入生成过程。我们这里用$y$表示外部信息，它可以通过一些网络结构（例如cross attention等）加入扩散模型中，我们由此可以训练$p_{\theta}(\x_t|\x_{t+1},y)$来实现基于外部信息的生成。但这种方式往往效果不佳【为什么？引用？】

为了克服这种问题，研究者提出了多种方法，在生成时加入额外的引导信号以提升生成质量。目前主流方法可分为分类器引导（classifier guidance）、无分类器引导（classifier-free guidance）和CLIP引导（CLIP guidance）。下面我们将首先描述在$y$参与生成时扩散模型的反向过程，随后介绍这三大类引导方法的具体实现。

我们参考\cite{dhariwal2021diffusion}，将从DDPM的视角描述外部信息$y$参与生成时扩散模型的反向过程，我们将此称为条件反向过程（conditional reverse process）。我们之前介绍了无条件的$p_{\theta}(\x_{t}|\x_{t+1})$的定义，我们希望在此基础上建立$p(\x_{t}|\x_{t+1},y)$的表达，具体地，我们有：
\begin{align}
\begin{split}
    p(\x_{t}|\x_{t+1},y) &= \frac{p(\x_{t},\x_{t+1},y)}{p(\x_{t+1},y)} = \frac{p(\x_{t},\x_{t+1},y)}{p(y|\x_{t+1})p(\x_{t+1})} = \frac{p(\x_{t},y|\x_{t+1})p(\x_{t+1})}{p(y|\x_{t+1})p(\x_{t+1})} \\
    &= \frac{p(\x_{t}|\x_{t+1}) p(y|\x_{t},\x_{t+1})p(\x_{t+1})}{p(y|\x_{t+1})p(\x_{t+1})} = \frac{p(\x_{t}|\x_{t+1}) p(y|\x_{t},\x_{t+1})}{p(y|\x_{t+1})}.
\end{split}
\label{conditional:1}
\end{align}
又因为
\begin{equation*}
    p(y|\x_{t},\x_{t+1})=p(\x_{t+1}|\x_t,y)\frac{p(y|\x_t)}{p(\x_{t+1}|\x_t)} = p(\x_{t+1}|\x_t)\frac{p(y|\x_t)}{p(\x_{t+1}|\x_t)} = p(y|\x_t),
\end{equation*}
即由$\x_t$预测外部信息$y$实际上不依赖于$\x_{t+1}$。将上式代入(\ref{conditional:1})中，可得
\begin{equation*}
    p(\x_{t}|\x_{t+1},y) = \frac{p(\x_{t}|\x_{t+1})p(y|\x_t)}{p(y|\x_{t+1})}.
\end{equation*}
又因为$p(y|\x_{t+1})$与$\x_{t}$的生成无关，所以我们可以将此项视作一个常数$Z$。此外，上式中的$p(\x_{t}|\x_{t+1})$实际上可以用之前介绍的神经网络$p_\theta(\x_{t}|\x_{t+1})$近似，于是我们有：
\begin{equation}
    p_{\theta}(\x_{t}|\x_{t+1},y) = \frac{1}{Z} p_\theta(\x_{t}|\x_{t+1})p(y|\x_t).
\label{conditional:backward}  
\end{equation}

之前在介绍DDPM时，我们在(\ref{ddpm:p_reverse})中给出了$p_\theta(\x_{t}|\x_{t+1})$的具体形式，这里我们简记为$p_\theta(\x_{t}|\x_{t+1})=\N(\mu,\Sigma)$，下面我们参考\cite{dhariwal2021diffusion}，给出$p_{\theta}(\x_{t}|\x_{t+1},y)$对应的高斯分布的均值和方差表达式。首先，由$p_{\theta}(\x_{t}|\x_{t+1})$的定义，我们可以将其对数似然写成：
\begin{equation*}
    \log p_{\theta}(\x_{t}|\x_{t+1}) = -\frac{1}{2}(\x_t-\mu)^{T}\Sigma^{-1}(\x_t-\mu) + C_0,
\end{equation*}
其中$C_0$是一个与$\x_t$无关的常数。此外，对于(\ref{conditional:backward})中的$p(y|\x_t)$的对数似然，我们可以通过其在$\x_t=\mu$处的Taylor展开进行近似：
\begin{equation*}
    \log p(y|\x_t)\approx \log p(y|\x_t)|_{\x_t=\mu} + (\x_t-\mu)\nabla_{\x_t} \log p(y|\x_t)|_{\x_t=\mu} = (\x_t-\mu)g + C_1,
\end{equation*}
其中我们用$g$表示$\nabla_{\x_t} \log p(y|\x_t)|_{\x_t=\mu}$，$C_1$是一个与$\x_t$无关的常数。根据上面两式，我们可以推导(\ref{conditional:backward})中$p_{\theta}(\x_{t}|\x_{t+1},y)$的对数似然如下：
\begin{align}
\begin{split}
    \log p_{\theta}(\x_{t}|\x_{t+1},y) &= \log(p_\theta(\x_{t}|\x_{t+1})p(y|\x_t)) + C_2 \\
    &\approx -\frac{1}{2}(\x_t-\mu)^{T}\Sigma^{-1}(\x_t-\mu) + (\x_t-\mu)g + C_3 \\
    &= -\frac{1}{2} (\x_t-\mu-\Sigma g)^{T}\Sigma^{-1}(\x_t-\mu-\Sigma g) + \frac{1}{2}g^T\Sigma g + C_3 \\
    &= -\frac{1}{2} (\x_t-\mu-\Sigma g)^{T}\Sigma^{-1}(\x_t-\mu-\Sigma g) + C_4
\end{split}
\label{conditional:backward_gaussian}
\end{align}
其中$C_2$，$C_3$和$C_4$都是与$\x_t$无关的常数。从(\ref{conditional:backward_gaussian})中我们可以看出$p_{\theta}(\x_{t}|\x_{t+1},y)$实际上服从高斯分布$\N(\mu+\Sigma g,\Sigma)$。下面我们三种常用的条件生成方法，它们实际上分别采用不同的方式来实现$p(y|\x_t)$。


分类器引导\cite{dhariwal2021diffusion}实际上通过训练一个分类器$p_{\phi}(y|\x_t)$（$\phi$表示模型参数）来实现$p(y|\x_t)$，分类器的梯度随后可对扩散模型施加条件约束，以让扩散模型更好地利用类别标签或文本进行条件生成。具体地，我们可以训练一个以带噪声样本$\x_t$为输入的分类器$p_{\phi}(y|\x_t)$。假设此时扩散模型的$p_{\theta}(\x_{t-1}|\x_t,y)$对应的高斯分布的均值和方差分别为$\mu_\theta(\x_t|y)$和$\Sigma_\theta(\x_t|y)$，那么由(\ref{conditional:backward_gaussian})可知，分类器引导的扩散模型的方差仍为$\Sigma_\theta(\x_t|y)$，均值为：
\begin{equation}
\hat{\mu}_{\theta}(\x_t|y)=\mu_{\theta}(\x_t|y) + s\cdot\Sigma_\theta(\x_t|y)\cdot\nabla_{\x_t}\log p_{\phi}(y|\x_t),
\label{conditional_classifier_guided}
\end{equation}
其中$s$是控制分类器引导强度的超参数。从直观上来看，分类器引导通过$\nabla_{\x_t}\log p_{\phi}(y|\x_t)$项，使得生成的样本与外部信息$y$的关联更强。分类器引导虽然在实践中展示出来有效性，但是这种方法需要单独在噪声样本上训练分类器，这带来了额外的计算和存储开销。

无分类器引导\cite{ho2022classifier}通过隐式地估计$p(y|\x_t)$来实现引导的目的。具体地，由Bayes公式，我们有：
\begin{equation*}
    p(y|\x_t) \propto \frac{p(\x_t|y)}{p(\x_t)},
\end{equation*}
所以我们可以推出：
\begin{equation*}
    \nabla_{\x_t}\log p(y|\x_t) \propto \nabla_{\x_t}\log \left(\frac{p(\x_t|y)}{p(\x_t)}\right) = \nabla_{\x_t}\log p(\x_t|y) -\nabla_{\x_t}\log p(\x_t).
\end{equation*}
我们这里采用\cite{ho2022classifier}中的符号表示，即我们现在已有DDPM扩散模型$\epsilon_\theta(\x_t|y)$，由我们之前的介绍可以知道，该去噪函数实际上正比于分数函数$\nabla_{\x_t}\log p(\x_t|y)$。于是实际我们进一步有：
\begin{align*}
    \nabla_{\x_t}\log p(y|\x_t) & \propto \nabla_{\x_t}\log p(\x_t|y) -\nabla_{\x_t}\log p(\x_t) \\
    &\propto \epsilon_\theta(\x_t|y) - \epsilon_\theta(\x_t).
\end{align*}
上式中$\epsilon_\theta(\x_t|y)$可以通过在DDPM的训练中融合外部信息$y$训练得到，而$\epsilon_\theta(\x_t)$可以通过在训练$\epsilon_\theta(\x_t|y)$中按一定概率将$y$设置成空白得到\cite{ho2022classifier}，我们将此情况对应的去噪函数记为$\epsilon_\theta(\x_t|\emptyset)$。从直观上来看，实际上\emph{有条件预测的噪声和无条件预测的噪声的差值，就是该条件对应的修正方向}。所以，我们最后可得无分类器引导的去噪函数如下：
\begin{equation}
    \hat{\epsilon}_\theta(\x_t|y) = \epsilon_\theta(\x_t|\emptyset) + s\cdot(\epsilon_\theta(\x_t|y) - \epsilon_\theta(\x_t|\emptyset)),
\label{conditional_classifier_free_guided}
\end{equation}
其中$s$是控制引导强度的超参数。无分类器引导具有两个显著优势。首先，它允许单个模型在直接利用自身习得的知识进行生成，而无需依赖另一个分类模型。其次，当需要基于难以通过分类器预测的信息（例如文本）进行条件生成时，这种引导方式能够显著简化条件控制流程。

CLIP（Contrastive Language-Image Pre-training）\cite{radford2021learning}是一种用于学习文本与图像联合表征的可扩展方法。CLIP模型由两个独立组件构成：图像编码器$f(x)$和文本编码器$g(y)$。CLIP模型基于海量的图像-文本对数据，通过优化对比损失（contrastive loss）\cite{oord2018representation}让成对的图像和文本特征相互靠近，不成对的图像和文本相互远离，以此学习良好的特征表示。

由于CLIP能够很好地度量图像与文本描述之间的匹配程度，多项研究\cite{clip-guide-1,Patashnik_2021_ICCV,gal2022StyleGAN}利用它引导生成对抗网络（GAN）等生成模型生成符合用户指定文本描述的图像。若将这一思路应用于扩散模型，我们可以用CLIP模型替代分类器指导中的分类器。具体而言，类似我们通过图像编码与文本编码的内积$f(\x_t)\cdot g(y)$来近似$p(y|\x_t)$，于是我们可以按如下方式对反向过程的高斯均值进行扰动：
\begin{equation}
\hat{\mu}_{\theta}(\x_t|y)=\mu_{\theta}(\x_t|y) + s\cdot\Sigma_\theta(\x_t|y)\cdot\nabla_{\x_t}(f(\x_t)\cdot g(y)),
\label{conditional_clip_guided}
\end{equation}
其中$s$是控制引导强度的超参数。与分类器指导类似，必须对CLIP模型施加噪声训练（即在噪声图像$\x_t$上训练），以确保反向过程中梯度计算的正确性，这实际上限制了该方法的可扩展性。

后续关于扩散模型的研究主要从三个方向改进经典方法（DDPMs、SGMs和Score SDEs）：（1）更快、更高效的采样；（2）更精确的似然与密度估计；（3）处理特殊结构数据（如具有排列不变性、流形结构和离散结构的数据）。我们将在接下来的分别对这些方向展开详细综述。

\section{扩散模型后续改进}


\newpage
\bibliography{ref}

\newpage
\appendix


\section{此处为附录}




\end{document}
