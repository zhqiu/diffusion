% !TeX root = main.tex
\documentclass[11pt,a4paper,UTF8]{ctexart}
\usepackage{quicklatex} % 引入自定义样式

\title{端侧文生多模态大模型文献综述}
\author{邱梓豪}
\date{\today}

\begin{document}



\maketitle
\tableofcontents
\newpage

\section{扩散模型基础}

在本文中，我们首先提供一个简洁但完善的扩散模型的基础知识介绍，它涵盖三种主要形式：去噪扩散概率模型（Denoising Diffusion Probabilistic Models，DDPMs）\cite{sohldickstein2015diffusion,ho2020denoising}、基于分数的生成模型（Score-based Generative Models，SGMs）\cite{song2019generative,song2020improved}以及随机微分方程（Stochastic Differential Equations，Score SDEs）\cite{song2020score}。这些方法的核心思想是通过逐渐增强的随机噪声对数据进行扰动（称为“扩散”过程），然后逐步去除噪声以生成新的数据样本。我们阐明了它们如何在相同的扩散原理下工作，并解释了这三种模型如何相互关联并可以相互转化。

我们首先定义扩散模型中的常用符号。设离散时间变量为$t\in\{0,1,\cdots,T\}$，连续时间变量为$t\in[0,T]$。设原始数据$\x_0\in\R^d$，其分布服从$q(\x_0)$，扩散模型通过向原始数据中不断加入高斯噪声，生成数据轨迹$\{\x_0,\x_1,\cdots,\x_T\}$，最终产生的$\x_T$趋近于纯高斯噪声。为了控制高斯噪声的添加强度，通常采用$\beta_t$（离散场景）或$\beta(t)dt$（连续场景）进行噪声调度。

\subsection{去噪扩散概率模型 (DDPM)}

去噪扩散概率模型（DDPM）使用两个马尔可夫链：一条前向链扰动数据直到变成噪声，另一条反向链将噪声转换回数据。前向链通常是人工设计的，目的是将任意数据分布转化为一个简单的先验分布（例如标准高斯分布），而反向马尔可夫链则通过学习由深度神经网络参数化的转移核（transition kernel）来逆转前向链的过程。随后，生成新数据点的过程首先从先验分布中采样一个随机向量，然后通过反向马尔可夫链进行采样，其中每一步都基于上一步的结果，该采样方式也称为\emph{祖先采样}\cite{koller2009probabilistic}。

下面我们给出上述过程的数学描述，给定数据分布$\x_0\sim q(\x_0)$，前向马尔可夫过程通过转移核$q(\x_t|\x_{t-1})$定义，并由此生成数据轨迹$\{\x_0,\x_1,\cdots,\x_T\}$。又马尔可夫性质，我们有：
\begin{equation*}
    q(\x_1,\cdots,\x_T|\x_0)=\Pi_{t=1}^T q(\x_t|\x_{t-1}).
\end{equation*}

在DDPM中，转移核$q(\x_t|\x_{t-1})$通常被设为高斯扰动形式，即：
\begin{equation*}
    q(\x_t|\x_{t-1}) =\N(\x_t;\sqrt{1-\beta_t}\x_{t-1},\beta_t\mathbf{I}),
\end{equation*}
其中$\beta_t\in(0,1)$是用于噪声调度的超参数，并在模型训练前被设置好,$\mathbf{I}$是对角矩阵。根据Sohl-Dickstein等人\cite{sohldickstein2015diffusion}的结论，使用上面的高斯扰动转移核的好处在于我们可以方便地获得某时间步$t\in\{0,1,\cdots,T\}$的数据$\x_t$的边缘分布。具体地，我们有：
\begin{equation*}
    q(\x_t|\x_0)=\N(\x_t;\sqrt{\bar{\alpha_t}}\x_0,(1-\bar{\alpha_t})\mathbf{I}),
\end{equation*}
其中$\alpha_t:=1-\beta_t$，$\bar{\alpha_t}:=\Pi_{s=0}^t\alpha_s$。于是，给定$\x_0$，我们可以首先采样一个高斯向量$\epsilon\in\N(0,\mathbf{I})$，随后通过如下变换得到$\x_t$的采样：
\begin{equation*}
    \x_t=\sqrt{\bar{\alpha_t}}\x_0 + (1-\bar{\alpha_t})\epsilon.
\end{equation*}
不难看出，由于$\bar{\alpha_T}\approx 0$，所以$\x_T$近似于高斯分布，故有：$q(\x_T)=\int q(\x_T|\x_0)q(\x_0)d\x_0\approx \N(\x_T;\mathbf{0},\mathbf{I})$。

直观地说，前向过程会逐渐向数据中注入噪声，直到所有结构完全消失。为了生成新的数据样本，DDPMs首先从先验分布中生成一个无结构的噪声向量，然后通过运行一个可学习的马尔可夫链在时间反方向上逐步去除噪声。具体来说，反向马尔可夫链由先验分布$p(\x_T)=\N(\x_T;\mathbf{0},\mathbf{I})$和一个\emph{可学习}的转移核$p_{\theta}(\x_{t-1}|\x_t)$参数化。先验分布的形式被设定为$p(\x_T)=\N(\x_T;\mathbf{0},\mathbf{I})$是因为前向过程产生的$\x_T$满足$q(\x_T)\approx \N(\x_T;\mathbf{0},\mathbf{I})$。可学习的转移核$p_{\theta}(\x_{t-1}|\x_t)$的形式为：
\begin{equation*}
    p_{\theta}(\x_{t-1}|\x_t) = \N(\x_{t-1};\mu_{\theta}(\x_t,t),\Sigma_{\theta}(x_t,t)),
\end{equation*}
其中$\theta$表示模型参数，高斯均值$\mu_{\theta}(\x_t,t)$和方差$\Sigma_{\theta}(x_t,t))$函数由深度神经网络进行参数化，并以带噪声的数据样本$\x_t$和时间$t$为输入。假设我们可以充分学习$p_{\theta}(\x_{t-1}|\x_t)$，那么便可以通过先从$p(\x_T)=\N(\x_T;\mathbf{0},\mathbf{I})$采样$\x_T$，再迭代式地调用$p_{\theta}(\x_{t-1}|\x_t)$（直到$t=1$）来生成样本$\x_0$。

现在我们介绍扩散模型的训练过程，即如何学出一个好的$p_{\theta}(\x_{t-1}|\x_t)$。训练的核心思想是\emph{最大化数据对数似然的变分下界（Evidence Lower Bound, ELBO）}，具体地，给定数据$\x_0\sim q(\x_0)$，反向模型生成$\x_0$的对数似然为$\log p_{\theta}(\x_0)$，下面我们推导其变分下界：
\begin{align}
\begin{split}
    \log p_{\theta}(\x_0) &= \log \int p_{\theta}(\x_0,\cdots,\x_T)d\x_{1:T} \\
    &= \log \int p_{\theta}(\x_0,\cdots,\x_T)\frac{q(\x_1,\cdots,\x_T|\x_0)}{q(\x_1,\cdots,\x_T|\x_0)}d\x_{1:T} \\
    &= \log \int q(\x_1,\cdots,\x_T|\x_0)\frac{p_{\theta}(\x_0,\cdots,\x_T)}{q(\x_1,\cdots,\x_T|\x_0)}d\x_{1:T} \\
    &= \log \E_q \left[\frac{p_{\theta}(\x_0,\cdots,\x_T)}{q(\x_1,\cdots,\x_T|\x_0)}\right] \\
    & \geq \E_q \left[\log \frac{p_{\theta}(\x_0,\cdots,\x_T)}{q(\x_1,\cdots,\x_T|\x_0)}\right].
\end{split}
\label{ddpm:1}
\end{align}
上面最后一个不等式基于的Jensen不等式。此外，由前向和反向过程的马尔可夫性质，即
\begin{align*}
    p_{\theta}(\x_0,\cdots,\x_T) &= p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)\Pi_{t=2}^T p_{\theta}(\x_{t-1}|\x_t) \\
    q(\x_1,\cdots,\x_T|\x_0) &= q(\x_T|\x_{T-1})\Pi_{t=1}^{T-1}q(\x_t|\x_{t-1}),
\end{align*}
我们可以进一步对(\ref{ddpm:1})进行展开，得到：
\begin{align}
\begin{split}
    &\log p_{\theta}(\x_0) \geq \E_q \left[\log \frac{p_{\theta}(\x_0,\cdots,\x_T)}{q(\x_1,\cdots,\x_T|\x_0)}\right] \\
    &= \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)\Pi_{t=2}^T p_{\theta}(\x_{t-1}|\x_t)}{q(\x_T|\x_{T-1})\Pi_{t=1}^{T-1}q(\x_t|\x_{t-1})} \right] \\
    &= \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)\Pi_{t=1}^{T-1} p_{\theta}(\x_{t}|\x_{t+1})}{q(\x_T|\x_{T-1})\Pi_{t=1}^{T-1}q(\x_t|\x_{t-1})} \right] \\
    &= \E_q\left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)}{q(\x_T|\x_{T-1})} \right] + \E_q\left[\log\Pi_{t=1}^{T-1}\frac{p_{\theta}(\x_{t}|\x_{t+1})}{q(\x_t|\x_{t-1})} \right] \\
    &= \E_q[\log p_{\theta}(\x_0|\x_1)] - \E_q[\text{KL}(q(\x_T|\x_{T-1}) \| p_{\theta}(\x_T))] -\Sigma_{t=1}^{T-1}\E_q[\text{KL}(q(\x_t|\x_{t-1}) \| p_{\theta}(\x_{t}|\x_{t+1}))],
\end{split}
\label{ddpm:2}
\end{align}
上面最后一个等式来自于KL散度的定义。此外，由于$p_{\theta}(\x_T)$的计算不需要扩散模型参与，实际上没有可学习参数，所以可以视为一个常数const。最终，我们可以得到如下的变分下界：
\begin{equation}
\log p_{\theta}(\x_0) \geq \E_q[\log p_{\theta}(\x_0|\x_1)]  -\Sigma_{t=1}^{T-1}\E_q[\text{KL}(q(\x_t|\x_{t-1}) \| p_{\theta}(\x_{t}|\x_{t+1}))] + \text{const}
\label{ddpm:3}
\end{equation}

当我们仔细观察上面的$\E_q[\text{KL}(q(\x_t|\x_{t-1}) \| p_{\theta}(\x_{t}|\x_{t+1}))]$项时，会发现该期望计算非常困难。具体来说，我们需要从分布$q(\x_{t-1},\x_{t+1}|\x_0)$中采样$\x_{t-1}$和$\x_{t+1}$来计算期望，而该分布的具体形式未知。

为了解决这个问题，我们可以使用若干由$q$函数定义的前向转移函数\emph{模拟出}一个反向转移函数来替代$q(\x_t|\x_{t-1})$，这个新的反向转移函数具有和$p_{\theta}(\x_t|\x_{t+1})$都是反向的，所以期望的计算可以大大简化。具体地，我们由Bayes定理，可得：
\begin{equation*}
    q(\x_t|\x_{t-1})=\frac{q(\x_{t-1}|\x_t)q(\x_t)}{q(\x_{t-1})},
\end{equation*}
又因为$\x_{t-1}$实际上是前向过程中由$\x_0$产生的，所以$\x_{t-1}$的分布依赖于$\x_0$，故我们将上式替换成下面的基于$\x_0$的形式：
\begin{equation}
    q(\x_t|\x_{t-1},\x_0)=\frac{q(\x_{t-1}|\x_t,\x_0)q(\x_t|\x_0)}{q(\x_{t-1}|\x_0)},
\label{ddpm:bayes}
\end{equation}
此时，我们可以根据(\ref{ddpm:1})推导出$\log p_{\theta}(\x_0)$的新变分下界如下：
\begin{align}
\begin{split}
    \log p_{\theta}(\x_0) & \geq \E_q \left[\log \frac{p_{\theta}(\x_0,\cdots,\x_T)}{q(\x_1,\cdots,\x_T|\x_0)}\right] \\
    &= \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)\Pi_{t=2}^T p_{\theta}(\x_{t-1}|\x_t)}{q(\x_1|\x_0)\Pi_{t=2}^T q(\x_t|\x_{t-1},\x_0)} \right] \\
    &= \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)}{q(\x_1|\x_0)} \right] + \E_q \left[\log \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_t|\x_{t-1},\x_0)} \right].
\end{split}
\label{ddpm:3}
\end{align}

随后，我们将(\ref{ddpm:bayes})代入(\ref{ddpm:3})的第二项，可得：
\begin{align}
\begin{split}
    \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_t|\x_{t-1},\x_0)} &= \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{\frac{q(\x_{t-1}|\x_t,\x_0)q(\x_t|\x_0)}{q(\x_{t-1}|\x_0)}} \\
    &= \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_{t-1}|\x_t,\x_0)}  \times \Pi_{t=2}^T \frac{q(\x_{t-1}|\x_0)}{q(\x_t|\x_0)} \\
    &= \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_{t-1}|\x_t,\x_0)}  \times \frac{q(\x_1|\x_0)}{q(\x_T|\x_0)},
\end{split}
\label{ddpm:4}
\end{align}
其中最后一个等式成立是因为对任意序列$a_1,a_2,\cdots,a_T$，有$\Pi_{t=2}^T\frac{a_{t-1}}{a_t}=\frac{a_1}{a_2}\times\frac{a_2}{a_3}\times\cdots\times\frac{a_{T-1}}{a_T}=\frac{a_1}{a_T}$。随后我们将(\ref{ddpm:4})代入(\ref{ddpm:3})中，可得：
\begin{align}
\begin{split}
    & \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)}{q(\x_1|\x_0)} \right] + \E_q \left[\log \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_t|\x_{t-1},\x_0)} \right] \\
    &= \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)}{q(\x_1|\x_0)} \right] + \E_q \left[\log \left(\Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_{t-1}|\x_t,\x_0)}  \times \frac{q(\x_1|\x_0)}{q(\x_T|\x_0)}\right) \right] \\
    &=\E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)}{q(\x_1|\x_0)} + \log \frac{q(\x_1|\x_0)}{q(\x_T|\x_0)} \right] + \E_q \left[\log \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_{t-1}|\x_t,\x_0)}  \right] \\
    &= \E_q \left[\log\frac{p_{\theta}(\x_T)p_{\theta}(\x_0|\x_1)}{q(\x_T|\x_0)} \right] + \E_q \left[\log \Pi_{t=2}^T \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_{t-1}|\x_t,\x_0)}  \right] \\
    &= \E_q [p_{\theta}(\x_0|\x_1)] + \E_q\left[\frac{p_{\theta}(\x_T)}{q(\x_T|\x_0)}\right] + \Sigma_{t=2}^T \E_q \log \frac{p_{\theta}(\x_{t-1}|\x_t)}{q(\x_{t-1}|\x_t,\x_0)} \\
    &= \E_q [p_{\theta}(\x_0|\x_1)] -\text{KL}(q(\x_T|\x_0)\| p_{\theta}(\x_T)) -  \Sigma_{t=2}^T \text{KL}(q(\x_{t-1}|\x_t,\x_0) \| p_{\theta}(\x_{t-1}|\x_t)),
\end{split}
\label{ddpm:5}
\end{align}
其中我们在最后一个等式中使用了KL散度的定义。由于上式中$p_{\theta}(\x_T)$不需要学习，所以$\text{KL}(q(\x_T|\x_0)\| p_{\theta}(\x_T))$可以视作常数，因此，我们可以得到下面的数据对数似然$\log p_{\theta}(\x_0)$的变分下界：
\begin{equation}
\log p_{\theta}(\x_0) \geq \E_q [\log p_{\theta}(\x_0|\x_1)] -  \Sigma_{t=2}^T \text{KL}(q(\x_{t-1}|\x_t,\x_0) \| p_{\theta}(\x_{t-1}|\x_t)) + \text{const}.
\label{ddpm:elbo}
\end{equation}
可以看出，计算(\ref{ddpm:elbo})中的KL项（本质上是期望）所需的$\x_t$和$\x_0$实际上可以从分布$q(\x_t|\x_0)$中采样得到，该分布具有简洁的形式，因此(\ref{ddpm:elbo})相比前面提到的(\ref{ddpm:3})计算上简单很多。于是我们可以定义\emph{变分下界损失}$\mathcal{L}_{\text{VLB}}$如下：
\begin{equation}
\mathcal{L}_{\text{VLB}} := -\E_q [\log p_{\theta}(\x_0|\x_1)] +  \Sigma_{t=2}^T \text{KL}(q(\x_{t-1}|\x_t,\x_0) \| p_{\theta}(\x_{t-1}|\x_t)),
\label{ddpm:loss_vlb}
\end{equation}
可以看出，最小化$\mathcal{L}_{\text{VLB}}$即是最大化(\ref{ddpm:elbo})中的变分下界，等价于最大化扩散模型生成数据的似然。


下一步我们要确定$q(\x_{t-1}|\x_t,\x_0)$的具体形式。由(\ref{ddpm:bayes})可知，$q(\x_{t-1}|\x_t,\x_0)$由$q(\x_{t}|\x_{t-1},\x_0)$、$q(\x_{t-1}|\x_0)$和$q(\x_{t}|\x_0)$决定，而由扩散模型前向过程的定义可知，这三项的表达式分别为：
\begin{align*}
    q(\x_{t}|\x_{t-1},\x_0) &= \N(\x_t|\sqrt{\alpha_t}\x_{t-1},(1-\alpha_t)\mathbf{I}),  \\
    q(\x_{t-1}|\x_0) &= \N(\x_{t-1}|\sqrt{\bar{\alpha}_{t-1}}\x_0,(1-\bar{\alpha}_{t-1})\mathbf{I}), \\
    q(\x_{t}|\x_0) &=\N(\x_{t}|\sqrt{\bar{\alpha}_{t}}\x_0,(1-\bar{\alpha}_{t})\mathbf{I}),
\end{align*}
所以，由(\ref{ddpm:bayes})，我们可以得到
\begin{equation*}
    q(\x_{t-1}|\x_t,\x_0) = \frac{\N(\x_t|\sqrt{\alpha_t}\x_{t-1},(1-\alpha_t)\mathbf{I})\N(\x_{t-1}|\sqrt{\bar{\alpha}_{t-1}}\x_0,(1-\bar{\alpha}_{t-1})\mathbf{I})}{\N(\x_{t}|\sqrt{\bar{\alpha}_{t}}\x_0,(1-\bar{\alpha}_{t})\mathbf{I})}.
\label{ddpm:dist_of_reverse_pre}
\end{equation*}

随后，我们实际上可以证明$q(\x_{t-1}|\x_t,\x_0)$也服从高斯分布，并具有$\N(\x_{t-1}|\A\x_t+\B\x_0,\C\mathbf{I})$的形式，为了确认$\A$，$\B$和$\C$的具体形式，我们可以首先将$\ref{ddpm:dist_of_reverse_pre}$中右侧三个高斯分布的乘积转化为指数之和，随后可以通过求一次导和二次导得到$\A$，$\B$和$\C$。这里我们暂时忽略具体过程，$q(\x_{t-1}|\x_t,\x_0)$的最后形式如下：
\begin{align}
\begin{split}
    q(\x_{t-1}|\x_t,\x_0) &= \N(\x_{t-1}|\mu_q(\x_t,\x_0),\Sigma_q(t)),\\
    \mu_q(\x_t,\x_0) &= \frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}}{1-\bar{\alpha}_t}\x_t + \frac{(1-\alpha_t)\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_t}\x_0 \\
    \Sigma_q(t) &= \frac{(1-\alpha_t)(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{I}  \stackrel{\text{def}}{=} \sigma_q^2(t)\mathbf{I},
\end{split}
\label{ddpm:dist_of_reverse}
\end{align}
其中$\bar{\alpha}_t=\Pi_{i=1}^t \alpha_i$。

现在我们已经得到了变分下界(\ref{ddpm:elbo})中$q(\x_{t-1}|\x_t,\x_0)$所具有的高斯形式，由于$p_{\theta}(\x_{t-1}|\x_t)$是可以设计的，所以我们选择将其也设置为一个高斯分布，因为两个高斯分布的KL散度是便于简化计算的。具体地，我们定义：
\begin{equation}
p_{\theta}(\x_{t-1}|\x_t) = \N(\x_{t-1}| \mu_{\theta}(\x_t,t), \sigma_q^2(t)\mathbf{I}),
\label{ddpm:p_reverse}
\end{equation}
其中均值向量$\mu_{\theta}(\x_t,t)$是由一个神经网络生成的，其具体形式我们将在后文中给出；至于方差，我们则是选择了与(\ref{ddpm:dist_of_reverse})中$q(\x_{t-1}|\x_t,\x_0)$相同的$\sigma_q^2(t)\mathbf{I})$。于是(\ref{ddpm:elbo})中的KL散度可以简化为
\begin{align}
\begin{split}
    & \text{KL}\left(q(\x_{t-1}|\x_t,\x_0) \| p_{\theta}(\x_{t-1}|\x_t)\right) \\
    &= \text{KL} \left(\N(\x_{t-1}|\mu_q(\x_t,\x_0),\sigma_q^2(t)\mathbf{I}) \| \N(\x_{t-1}| \mu_{\theta}(\x_t,t), \sigma_q^2(t)\mathbf{I})\right) \\
    &= \frac{1}{2\sigma_q^2(t)} \| \mu_q(\x_t,\x_0) - \mu_{\theta}(\x_t,t) \|^2,
\label{ddpm:elbo_simp_1}
\end{split}
\end{align}
在上面的推导中，我们使用了两个方差相同的高斯分布的KL散度实际上是这两个分布均值向量的欧式距离这一关系。

此外，对于变分下界(\ref{ddpm:elbo})中的$\log p_{\theta}(\x_0|\x_1)$可以进行如下简化：
\begin{align}
\begin{split}
\log p_{\theta}(\x_0|\x_1) &= \log \N(\x_0| \mu_{\theta}(\x_1,1),\sigma_q^2(1)\mathbf{I}) \\
&= \log \left( \frac{1}{\left(\sqrt{2\pi\sigma_q^2(1)} \right)^d} \right)\exp \left\{-\frac{\|\x_0 -\mu_{\theta}(\x_1,1) \|^2}{2\sigma_q^2(1)} \right\} \\
&= -\frac{\|\x_0 -\mu_{\theta}(\x_1,1) \|^2}{2\sigma_q^2(1)} -\frac{d}{2}\log (2\pi\sigma_q^2(1)),
\label{ddpm:elbo_simp_2}
\end{split}
\end{align}
可以看出(\ref{ddpm:elbo_simp_1})和(\ref{ddpm:elbo_simp_2})从优化目标上实际上是统一的，都是\emph{最小化前向过程产生的数据轨迹和对应的反向过程生成的数据轨迹的欧式距离}。

下面，我们在对$\mu_q(\x_t,\x_0)$的具体形式进行分析，并由此设计$\mu_{\theta}(\x_t,t)$的计算方式，最后完成DDPM目标函数的推导。我们由$q(\x_t|\x_0)$的表达式可知：
\begin{equation*}
    \x_t =\sqrt{\bar{\alpha}_t}\x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon_0 \Rightarrow  \x_0 =\frac{\x_t - \sqrt{1-\bar{\alpha}_t}\epsilon_0}{\sqrt{\bar{\alpha}_t}}.
\end{equation*}
随后我们将上式代入(\ref{ddpm:dist_of_reverse})中$\mu_q(\x_t,\x_0)$的表达式，可以得到：
\begin{align}
\begin{split}
    \mu_q(\x_t,\x_0) &= \frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\x_t +(1-\alpha_t)\sqrt{\bar{\alpha}_{t-1}}\x_0 }{1-\bar{\alpha}_t} \\
    &= \frac{(1-\bar{\alpha}_{t-1})\sqrt{\alpha_t}\x_t +(1-\alpha_t)\sqrt{\bar{\alpha}_{t-1}}\frac{\x_t - \sqrt{1-\bar{\alpha}_t}\epsilon_0}{\sqrt{\bar{\alpha}_t}} }{1-\bar{\alpha}_t}\\
    &= \frac{1}{\sqrt{\alpha_t}}\x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}\sqrt{\alpha_t}}\epsilon_0,
\end{split}
\label{ddpm:mu_q}
\end{align}
上式实际上将$\mu_q(\x_t,\x_0)$由关于$\x_0$的函数转化成关于高斯噪声$\epsilon_0$的函数。

下面我们将设计一个更合适的$\mu_{\theta}(\x_t,t)$的形式，使之适配$\mu_q(\x_t,\x_0)$的表达式，具体地，我们进行如下设计：
\begin{equation}
\mu_{\theta}(\x_t,t)=\frac{1}{\sqrt{\alpha_t}}\x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}\sqrt{\alpha_t}}\epsilon_{\theta}(\x_t,t),
\label{ddpm:mu_theta}
\end{equation}
值得注意的是，我们此时让模型预测第$t$步中向$\x_t$中加入的噪声，即$\epsilon_{\theta}(\x_t,t)$。

最后，我们将(\ref{ddpm:elbo_simp_1})、(\ref{ddpm:elbo_simp_2})、(\ref{ddpm:mu_q})和(\ref{ddpm:mu_theta})代入(\ref{ddpm:elbo})，并结合(\ref{ddpm:loss_vlb})的定义，可得：
\begin{equation}
\mathcal{L}_{\text{VLB}} = -\sum_{t=1}^T \E_q \left[\frac{1}{2\sigma_q^2(t)}\frac{(1-\alpha_t)^2}{(1-\bar{\alpha}_t)\alpha_t}\|\epsilon_{\theta}(\x_t,t)-\epsilon_0 \|^2 \right],
\label{ddpm:loss_vlb_denoise}
\end{equation}
于是我们最终得到了DDPM的目标函数，它实际上是一个监督学习型的目标函数，即训练扩散模型的输出，即$\epsilon(\x_t,t)$，来预测前向过程中每一步加入的噪声$\epsilon_0$。注意，实际上加入的噪声是$\epsilon_0$乘上某系数，但我们设计扩散模型反向过程中也让$\epsilon(\x_t,t)$乘上此系数，所以在(\ref{ddpm:loss_vlb_denoise})中该系数可以被提取出来，形成系数$\frac{1}{2\sigma_q^2(t)}\frac{(1-\alpha_t)^2}{(1-\bar{\alpha}_t)\alpha_t}$。

最后我们介绍扩散模型的生成过程。在训练结束后，我们可以获得神经网络$\epsilon_{\theta}(\x_t,t)$。生成新样本时，我们先采样一个高斯白噪声$\x_T\sim\N(\mathbf{0},\mathbf{I})$，随后便可以利用(\ref{ddpm:p_reverse})中建立的$\x_{t-1}$与$\x_t$的关系以及(\ref{ddpm:mu_theta})中$\mu_\theta$的定义，迭代式地生成$\x_{T-1},\cdots,\x_0$，具体的计算方式为：
\begin{equation*}
    \x_{t-1} = \frac{1}{\sqrt{\alpha_t}}\left(\x_t -\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon(\x_t,t) \right) + \sigma_q(t)\z,\quad \z\sim\N(\mathbf{0},\mathbf{I}).
\end{equation*}

\subsection{基于分数的生成模型 (SGM)}

基于分数的生成模型的核心是Stein分数函数（简称分数函数）\cite{Hyvrinen2005EstimationON}。给定一个样本概率密度函数$p(\x)$，其分数函数被定义为对数概率密度的梯度：
\begin{equation*}
    \s_\theta(\x) := \nabla_{\x}\log p(\x).
\end{equation*}
注意不同于统计领域常见的Fisher分数$\nabla_\theta \log p_{\theta}(\x)$，Stein分数是关于\emph{样本}的梯度，而不是关于模型参数$\theta$的梯度。该分数函数实际上是数据分布的梯度场，它指向使数据出现概率增加最快的方向。

前人提出了多种方法来学习分数函数。一种方法称为显式分数函数匹配（Explicit Score Matching，ESM）\cite{vincent2011connection}。假设我们有一个包含$M$个样本的数据集$\X=\{\x^{(1)},\cdots,\x^{(M)}\}$，那么我们可以通过核密度估计来近似真实数据分布$p(\x)$：
\begin{equation*}
    q_h(\x)=\frac{1}{M}\sum_{m=1}^M \frac{1}{h} K\left(\frac{\x-\x^{(m)}}{h} \right),
\end{equation*}
其中$K(\cdot)$是核函数，$h$是核函数的超参数。随后显式分数函数匹配基于$q_h(\x)$来学习分数函数$\s_\theta(\x)$，目标函数如下：
\begin{equation*}
    \mathcal{L}_{\text{ESM}}:=\frac{1}{2}\E_{p(\x)} \|\s_\theta(\x)-\nabla_{\x}\log p(\x) \|^2 \approx \frac{1}{2}\E_{q_h(\x)} \| s_\theta(\x)-\nabla_{\x}\log q_h(\x)\|^2.
\end{equation*}
该方法的主要问题在于核密度是非参数化的、它对真实分布的近似能力很有限，尤其是当样本数量有限或数据处于高维空间时，核密度估计的效果会较差。

为了避免近似真实数据分布，\cite{Hyvrinen2005EstimationON}提出了隐式分数函数匹配（Implicit Score Matching，ISM），其目标函数为：
\begin{equation*}
    \mathcal{L}_{\text{ISM}}:=\E_{p(\x)} \left[\text{Tr}(\nabla_{\x} \s_\theta (\x)) + \frac{1}{2}\|\s_\theta (\x) \|^2 \right],
\end{equation*}
其中$\nabla_{\x} \s_\theta (\x)$表示$\s_\theta (\x)$的Jacobian。尽管该方法避免了直接近似真实数据分布$p(\x)$，但\cite{song2019generative}指出该目标函数的迹函数难以计算，导致该方法缺乏可扩展性。

现在最流行的分数函数学习方法是基于去噪分数函数匹配（Denoising Score Matching，DSM）\cite{vincent2011connection}，其目标函数如下：
\begin{equation}
\mathcal{L}_{\text{DSM}}(\theta):=\E_{q(\x,\x^\prime)} \left[\frac{1}{2}\| \s_{\theta}(\x) - \nabla_{\x}\log q(\x|\x^\prime) \|^2 \right]，
\label{sgm:dsm}
\end{equation}
其中$\x$是某给定样本，$\x^\prime$是在该样本上加入噪声生成的，可以看出DSM实际上基于噪声样本$\x^\prime$找出无噪声样本出现概率增加最快的方向，这就解释了该方法为什么包含“去噪”一词。由于该目标函数不涉及对真实分布的估计以及难以计算的迹函数，所以DSM得到了广泛使用。

为了更好的优化上面的目标函数，一般可以设置$q(\x,\x^\prime)=\N(\x|\x^\prime,\sigma^2)$，即$\x=\x^\prime+\sigma\z,\z\sim\N(\mathbf{0},\mathbf{I})$。于是我们有：
\begin{align*}
    \nabla_{\x}\log q(\x|\x^\prime) &= \nabla_{\x}\log \frac{1}{(\sqrt{2\pi\sigma^2})^d}\exp\left\{-\frac{\|\x-\x^\prime \|^2}{2\sigma^2}\right\} \\
    &= \nabla_{\x} \left\{ -\frac{\|\x-\x^\prime \|^2}{2\sigma^2} -\frac{d}{2}\log (2\pi\sigma^2) \right\} \\
    &= -\frac{\x-\x^\prime}{\sigma^2}=-\frac{\z}{\sigma}.
\end{align*}

于是(\ref{sgm:dsm})中的目标函数变成：
\begin{equation}
\mathcal{L}_{\text{DSM}}(\theta):=\E_{q(\x,\x^\prime)} \left[\frac{1}{2}\| \s_{\theta}(\x) - \nabla_{\x}\log q(\x|\x^\prime) \|^2 \right] = \E_{q(\x^\prime)} \left[ \s_\theta(\x^\prime +\sigma\z)+\frac{\z}{\sigma} \right].
\label{sgm:dsm_obj}
\end{equation}
可以看出，上面的目标函数的作用，就是训练分数函数$\s_\theta$，让其预测输入样本中的噪声（乘上系数$1/\sigma^2$）。

尽管目标函数(\ref{sgm:dsm_obj})简洁且方便计算优化，但\cite{song2019generative}指出由于真实世界数据常呈现低维流形分布，所以分数函数在一些区域可能无定义；此外低密度区域的数据少，导致该区域的分数函数难以准确估计。为了应对这两个挑战，\cite{song2019generative}提出NCSN（Noise Conditional Score Network）方法采用不同强度的随机高斯噪声对数据进行扰动。具体地，。。。

我们可以看出，一开始向原始数据加入小尺度的噪声，这能能保证图像平滑变化，降低分数函数的学习难度，并在生成时提升图像保真度；后来逐渐加入大尺度噪声，这样能有效填充原始数据分布中的低密度区域，为分数函数的学习提供更多训练信号以提升估计精度。



现在，我们学到了分数函数，那么此时便可以利用该函数找到数据分布的高概率区域并从中采样得到出现概率大（即较为真实）的样本。



\subsection{随机微分方程 (Score SDE)}


\newpage
\bibliography{ref}

\newpage
\appendix


\section{此处为附录}




\end{document}
